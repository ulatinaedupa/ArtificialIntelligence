{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)->Literal[END, \"summarize_conversation\"]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9bddfca6e2', 'id': 'chatcmpl-BYmNAcBMqxaBy1VU3Q6dZD2QXM7ys', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5081a5aa-3337-4a70-8a83-b99c3cc4f96d-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's great to hear from you. How can I help you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "#input_message = \"hi! I'm Lance\"\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Key', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Points', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='St', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='adium', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' play', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' moved', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Before', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='lestick', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Park', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Masc', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' red', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' white', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' mascot', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' S', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ourd', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ough', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='Champ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ionship', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='X', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='VI', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' period', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' early', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' conference', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Ronnie', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' L', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ott', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Haley', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' instrumental', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' championship', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='Co', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='aching', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Management', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' coaches', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Bill', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' credited', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='izing', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='West', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Off', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ense', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',\"', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' George', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Se', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='if', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ert', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' As', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ival', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' intense', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' notably', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' fueled', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' high', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-st', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='akes', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' match', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ups', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='Recent', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' reaching', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' losing', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' building', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' mix', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' veteran', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' leadership', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' young', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' talent', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' contributions', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' development', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content=' popularity', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_76544d79cb', 'service_tier': 'default'}, id='run--80fca8aa-f6c8-4fb2-95fa-d43a486b6394')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| The| team| was| founded| in| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "\n",
      "|###| Key| Points|:\n",
      "\n",
      "|-| **|St|adium|**|:| The| |49|ers| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|,| California|,| which| they| moved| to| in| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|-| **|Team| Colors|**|:| The| team's| colors| are| red|,| gold|,| and| white|.\n",
      "\n",
      "|-| **|Masc|ot|**|:| The| |49|ers|'| mascot| is| S|ourd|ough| Sam|.\n",
      "\n",
      "|-| **|Champ|ionship|s|**|:| The| |49|ers| have| won| five| Super| Bowl| championships| (|Super| Bowl| XVI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|),| with| their| most| successful| period| being| the| |198|0|s| and| early| |199|0|s|.\n",
      "\n",
      "|-| **|Not|able| Players|**|:| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| Charles| Haley|.\n",
      "\n",
      "|-| **|Co|aching| and| Management|**|:| The| team| has| been| led| by| several| notable| coaches|,| including| Bill| Walsh|,| who| is| credited| with| popular|izing| the| West| Coast| offense|.| As| of| my| last| update|,| Kyle| Shan|ahan| is| the| head| coach|.\n",
      "\n",
      "|-| **|R|ival|ries|**|:| The| |49|ers| have| notable| rival|ries| with| the| Seattle| Seahawks|,| Los| Angeles| Rams|,| and| historically| with| the| Dallas| Cowboys| and| Green| Bay| Packers|.\n",
      "\n",
      "|-| **|Ownership|**|:| The| team| is| owned| by| the| York| family|,| with| Jed| York| serving| as| the| CEO|.\n",
      "\n",
      "|The| |49|ers| have| a| rich| history| and| are| known| for| their| innovative| play| style| and| success| in| the| NFL|,| particularly| during| their| dynasty| years| in| the| |198|0|s| and| |199|0|s|.| They| continue| to| be| a| competitive| team| in| the| league|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f028256-1349-6627-9994-9f5fd44b23c6', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0471589d-eb6a-4409-863b-7f43cc39bf0c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0471589d-eb6a-4409-863b-7f43cc39bf0c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BT7WnhTqvFjSGoj7qHAWkzPbjcXQP', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-2e661078-edcd-4840-ba8d-3241dffcfed5-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0471589d-eb6a-4409-863b-7f43cc39bf0c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BT7WnhTqvFjSGoj7qHAWkzPbjcXQP', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-2e661078-edcd-4840-ba8d-3241dffcfed5-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '7403ec98-fac8-4981-8987-6243de1056a0', 'tool_call_id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0471589d-eb6a-4409-863b-7f43cc39bf0c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BT7WnhTqvFjSGoj7qHAWkzPbjcXQP', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-2e661078-edcd-4840-ba8d-3241dffcfed5-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '7403ec98-fac8-4981-8987-6243de1056a0', 'tool_call_id': 'call_BCmFVNmeXLHBwlYDMLZmNrQD', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 15, 'prompt_tokens': 159, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BT7WqH1QHxEtGfTniaSKQShj2Ayre', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-87dbb322-6d9b-4a73-8ff5-ea0eba681039-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 15, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='e96b8a94-1372-4653-80d8-5fba09f816eb'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [{'id': 'call_zNEkLUT5MMz4XfSziFMK9Ko9', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYmZlyRyPY6R7cLCZF0c9tM8Hi1sZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--112a1a95-aca6-4242-8b2c-3765dc0eeb82-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_zNEkLUT5MMz4XfSziFMK9Ko9', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='91d320a2-0707-4b40-8b90-c9ac482c60c7' tool_call_id='call_zNEkLUT5MMz4XfSziFMK9Ko9'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BYmZlbKEXSJrw3HvU1S7b2IEIhm3T', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--5fb4c7bb-7482-4a15-b4dc-8214ca3fec27-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1f0346b8-25ce-6660-b4a5-3dbf8d4852ed\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_NnnGApHxGeQOHyrIxNwJBrP1, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The product\n",
      "--------------------------------------------------\n",
      "AI: The product of\n",
      "--------------------------------------------------\n",
      "AI: The product of \n",
      "--------------------------------------------------\n",
      "AI: The product of 2\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and \n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The product of 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
